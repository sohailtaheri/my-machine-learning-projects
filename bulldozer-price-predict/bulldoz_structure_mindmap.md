# Bulldozer Price Predictor - Code Structure Mindmap

```
bulldoz.py
â”‚
â”œâ”€â”€ ğŸ“¦ IMPORTS
â”‚   â”œâ”€â”€ numpy (np)
â”‚   â”œâ”€â”€ pandas (pd)
â”‚   â”œâ”€â”€ matplotlib.pyplot (plt)
â”‚   â””â”€â”€ sklearn
â”‚       â”œâ”€â”€ RandomForestRegressor
â”‚       â”œâ”€â”€ RandomizedSearchCV
â”‚       â””â”€â”€ metrics (mean_squared_log_error, mean_absolute_error, r2_score)
â”‚
â”œâ”€â”€ ğŸ¯ MAIN CLASS: BulldozerPricePredictor
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ”§ Constructor & Attributes
â”‚   â”‚   â””â”€â”€ __init__(random_state=42)
â”‚   â”‚       â”œâ”€â”€ self.random_state
â”‚   â”‚       â”œâ”€â”€ self.model
â”‚   â”‚       â”œâ”€â”€ self.df
â”‚   â”‚       â”œâ”€â”€ self.df_preprocessed
â”‚   â”‚       â”œâ”€â”€ self.X_train
â”‚   â”‚       â”œâ”€â”€ self.y_train
â”‚   â”‚       â”œâ”€â”€ self.X_valid
â”‚   â”‚       â””â”€â”€ self.y_valid
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“¥ DATA LOADING
â”‚   â”‚   â””â”€â”€ load_data(filepath, parse_dates=True)
â”‚   â”‚       â”œâ”€â”€ Reads CSV file
â”‚   â”‚       â”œâ”€â”€ Parses saledate column
â”‚   â”‚       â”œâ”€â”€ Sorts by date
â”‚   â”‚       â””â”€â”€ Returns: pd.DataFrame
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ”„ DATA PREPROCESSING
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ add_datetime_features(df)
â”‚   â”‚   â”‚   â”œâ”€â”€ Extracts from saledate:
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ saleYear
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ saleMonth
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ saleDay
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ saleDayofweek
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ saleDayofyear
â”‚   â”‚   â”‚   â”œâ”€â”€ Drops saledate column
â”‚   â”‚   â”‚   â””â”€â”€ Returns: pd.DataFrame
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ handle_missing_values(df)
â”‚   â”‚   â”‚   â”œâ”€â”€ For Numerical Columns:
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Add "_is_missing" indicator
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ Fill with median
â”‚   â”‚   â”‚   â”œâ”€â”€ For Categorical Columns:
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Convert strings to categories
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Add "_is_missing" indicator
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ Convert to numeric codes (+1)
â”‚   â”‚   â”‚   â””â”€â”€ Returns: pd.DataFrame
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ preprocess_data(df)
â”‚   â”‚       â”œâ”€â”€ Calls add_datetime_features()
â”‚   â”‚       â”œâ”€â”€ Calls handle_missing_values()
â”‚   â”‚       â””â”€â”€ Returns: pd.DataFrame
â”‚   â”‚
â”‚   â”œâ”€â”€ âœ‚ï¸ DATA SPLITTING
â”‚   â”‚   â””â”€â”€ split_data(df, split_year=2012, target_col="SalePrice")
â”‚   â”‚       â”œâ”€â”€ Splits by year
â”‚   â”‚       â”œâ”€â”€ Training: year != 2012
â”‚   â”‚       â”œâ”€â”€ Validation: year == 2012
â”‚   â”‚       â”œâ”€â”€ Separates X and y
â”‚   â”‚       â””â”€â”€ Returns: (X_train, y_train, X_valid, y_valid)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ¤– MODEL TRAINING
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ train(n_estimators, max_depth, max_features, ...)
â”‚   â”‚   â”‚   â”œâ”€â”€ Creates RandomForestRegressor
â”‚   â”‚   â”‚   â”œâ”€â”€ Configurable hyperparameters:
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ n_estimators (default: 40)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ max_depth (default: 10)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ max_features (default: 0.5)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ min_samples_split (default: 14)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ min_samples_leaf (default: 3)
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ max_samples (default: None)
â”‚   â”‚   â”‚   â”œâ”€â”€ Fits model on training data
â”‚   â”‚   â”‚   â””â”€â”€ Returns: RandomForestRegressor
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ hyperparameter_tuning(param_grid, n_iter=20, cv=5, ...)
â”‚   â”‚       â”œâ”€â”€ Uses RandomizedSearchCV
â”‚   â”‚       â”œâ”€â”€ Default parameter grid:
â”‚   â”‚       â”‚   â”œâ”€â”€ n_estimators: [10-100]
â”‚   â”‚       â”‚   â”œâ”€â”€ max_depth: [None, 3, 5, 10]
â”‚   â”‚       â”‚   â”œâ”€â”€ min_samples_split: [2-20]
â”‚   â”‚       â”‚   â”œâ”€â”€ min_samples_leaf: [1-20]
â”‚   â”‚       â”‚   â””â”€â”€ max_features: [0.5, 1, "sqrt"]
â”‚   â”‚       â”œâ”€â”€ Performs cross-validation
â”‚   â”‚       â”œâ”€â”€ Updates self.model with best estimator
â”‚   â”‚       â””â”€â”€ Returns: RandomizedSearchCV
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“Š MODEL EVALUATION
â”‚   â”‚   â””â”€â”€ evaluate(verbose=True)
â”‚   â”‚       â”œâ”€â”€ Makes predictions on train & validation
â”‚   â”‚       â”œâ”€â”€ Calculates metrics:
â”‚   â”‚       â”‚   â”œâ”€â”€ Training MAE
â”‚   â”‚       â”‚   â”œâ”€â”€ Validation MAE
â”‚   â”‚       â”‚   â”œâ”€â”€ Training RMSLE
â”‚   â”‚       â”‚   â”œâ”€â”€ Validation RMSLE
â”‚   â”‚       â”‚   â”œâ”€â”€ Training RÂ²
â”‚   â”‚       â”‚   â””â”€â”€ Validation RÂ²
â”‚   â”‚       â””â”€â”€ Returns: dict of scores
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ”® PREDICTIONS
â”‚   â”‚   â”œâ”€â”€ predict(X)
â”‚   â”‚   â”‚   â”œâ”€â”€ Makes predictions on new data
â”‚   â”‚   â”‚   â””â”€â”€ Returns: np.array
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ save_predictions(test_data_path, output_path, id_col)
â”‚   â”‚       â”œâ”€â”€ Loads test data
â”‚   â”‚       â”œâ”€â”€ Preprocesses test data
â”‚   â”‚       â”œâ”€â”€ Ensures column alignment
â”‚   â”‚       â”œâ”€â”€ Makes predictions
â”‚   â”‚       â”œâ”€â”€ Creates submission DataFrame
â”‚   â”‚       â”œâ”€â”€ Saves to CSV
â”‚   â”‚       â””â”€â”€ Returns: pd.DataFrame
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ˆ VISUALIZATION
â”‚       â””â”€â”€ plot_feature_importance(n=20, figsize=(10, 8))
â”‚           â”œâ”€â”€ Extracts feature importances
â”‚           â”œâ”€â”€ Sorts by importance
â”‚           â”œâ”€â”€ Creates horizontal bar plot
â”‚           â”œâ”€â”€ Shows top n features
â”‚           â””â”€â”€ Returns: matplotlib.figure.Figure
â”‚
â”œâ”€â”€ ğŸ”§ STANDALONE FUNCTIONS
â”‚   â”‚
â”‚   â”œâ”€â”€ rmsle(y_true, y_pred)
â”‚   â”‚   â”œâ”€â”€ Calculates Root Mean Squared Log Error
â”‚   â”‚   â”œâ”€â”€ Uses sklearn's mean_squared_log_error
â”‚   â”‚   â””â”€â”€ Returns: float
â”‚   â”‚
â”‚   â””â”€â”€ preprocess_data_standalone(df)
â”‚       â”œâ”€â”€ Independent preprocessing function
â”‚       â”œâ”€â”€ Adds datetime features
â”‚       â”œâ”€â”€ Handles missing values
â”‚       â””â”€â”€ Returns: pd.DataFrame
â”‚
â””â”€â”€ ğŸš€ MAIN EXECUTION
    â””â”€â”€ main()
        â”œâ”€â”€ 1. Initialize predictor
        â”œâ”€â”€ 2. Load data
        â”œâ”€â”€ 3. Preprocess data
        â”œâ”€â”€ 4. Split data (year 2012 for validation)
        â”œâ”€â”€ 5. Train model (with optimal hyperparameters)
        â”œâ”€â”€ 6. Evaluate model
        â”œâ”€â”€ 7. Plot feature importance
        â”œâ”€â”€ 8. Save predictions
        â””â”€â”€ Returns: None


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

WORKFLOW: Complete ML Pipeline
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    START
      â”‚
      â”œâ”€â†’ [1] LOAD DATA
      â”‚     â””â”€â†’ load_data()
      â”‚
      â”œâ”€â†’ [2] PREPROCESS
      â”‚     â”œâ”€â†’ add_datetime_features()
      â”‚     â””â”€â†’ handle_missing_values()
      â”‚
      â”œâ”€â†’ [3] SPLIT DATA
      â”‚     â””â”€â†’ split_data()
      â”‚           â”œâ”€â†’ Train Set (pre-2012)
      â”‚           â””â”€â†’ Validation Set (2012)
      â”‚
      â”œâ”€â†’ [4] TRAIN MODEL
      â”‚     â”œâ”€â†’ Option A: train() [with known hyperparameters]
      â”‚     â””â”€â†’ Option B: hyperparameter_tuning() [auto-tune]
      â”‚
      â”œâ”€â†’ [5] EVALUATE
      â”‚     â””â”€â†’ evaluate()
      â”‚           â”œâ”€â†’ MAE
      â”‚           â”œâ”€â†’ RMSLE (competition metric)
      â”‚           â””â”€â†’ RÂ² Score
      â”‚
      â”œâ”€â†’ [6] ANALYZE
      â”‚     â””â”€â†’ plot_feature_importance()
      â”‚
      â”œâ”€â†’ [7] PREDICT
      â”‚     â””â”€â†’ save_predictions()
      â”‚           â”œâ”€â†’ Load test data
      â”‚           â”œâ”€â†’ Preprocess
      â”‚           â””â”€â†’ Generate submission.csv
      â”‚
    END


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

KEY DESIGN PATTERNS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¨ Object-Oriented Design
   â””â”€â†’ Single class encapsulates entire ML pipeline

ğŸ”„ Pipeline Pattern
   â””â”€â†’ Sequential steps: Load â†’ Preprocess â†’ Split â†’ Train â†’ Evaluate

ğŸ¯ Separation of Concerns
   â”œâ”€â†’ Data handling methods
   â”œâ”€â†’ Preprocessing methods
   â”œâ”€â†’ Model training methods
   â””â”€â†’ Evaluation/visualization methods

ğŸ“¦ Encapsulation
   â””â”€â†’ Internal state (df, model, X_train, etc.) protected in class

â™»ï¸ Reusability
   â”œâ”€â†’ Standalone functions for common operations
   â””â”€â†’ Configurable parameters with sensible defaults

ğŸ”§ Flexibility
   â”œâ”€â†’ Custom hyperparameters
   â”œâ”€â†’ Optional hyperparameter tuning
   â””â”€â†’ Verbose/quiet modes


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

USAGE EXAMPLES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Example 1: Basic Usage
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from bulldoz import BulldozerPricePredictor

predictor = BulldozerPricePredictor()
predictor.load_data("data/TrainAndValid.csv")
df = predictor.preprocess_data(predictor.df)
predictor.split_data(df)
predictor.train()
predictor.evaluate()


Example 2: With Hyperparameter Tuning
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
predictor = BulldozerPricePredictor()
predictor.load_data("data/TrainAndValid.csv")
df = predictor.preprocess_data(predictor.df)
predictor.split_data(df)
predictor.hyperparameter_tuning(n_iter=20, cv=5)
predictor.evaluate()


Example 3: Quick Prediction
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
predictor = BulldozerPricePredictor()
# ... load and train model ...
predictor.save_predictions(
    test_data_path="data/Test.csv",
    output_path="submission.csv"
)


Example 4: Standalone Preprocessing
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from bulldoz import preprocess_data_standalone

df = pd.read_csv("data.csv", parse_dates=["saledate"])
df_processed = preprocess_data_standalone(df)


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```
